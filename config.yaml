# Configuration for CXR Classification Training

# Model Configuration
model:
  name: "BioViL"  # Options: BioViL, MedKLIP, densenet121, densenet161, resnet50
  pretrained: true
  num_classes: 14
  freeze_backbone: false  # Whether to freeze pretrained weights

# Data Configuration
data:
  datadir: "/mnt/DGX01/Personal/4jh/cxr/MIMIC-CXR-JPG"
  image_subdir: "files"
  dicom_id_file: null  # Optional: CSV file to restrict specific dicom_ids
  label_method: "zeros_uncertain_nomask"  # Label handling method

  # Cross-validation settings
  split_type: "cv"  # Options: official, cv
  num_folds: 10
  fold: 0
  val_size: 0.1
  random_state: 0
  stratify: false

# Training Configuration
training:
  num_epochs: 100
  batch_size: 64
  learning_rate: 1e-3
  optimizer: "adam"  # Options: adam, sgd
  weight_decay: 0.0

  # Learning rate scheduling
  lr_scheduler:
    enabled: true
    patience: 3  # Reduce LR if val loss increases for this many epochs
    factor: 0.5
    early_stop_patience: 10  # Stop if no improvement for this many epochs

  # Validation
  val_iters: null  # Validate every N iterations, null for once per epoch

  # Mixed precision
  amp: false

  # Distributed training
  distributed: false
  single_node_parallel: false

# Data Augmentation (training only)
augmentation:
  horizontal_flip: 0.5
  rotation_degrees: 20
  random_crop: false
  color_jitter: false

# Output Configuration
output:
  dir: "./outputs/experiment_1"
  save_frequency: 1  # Save checkpoint every N epochs

# System Configuration
system:
  num_workers: 8
  pin_memory: true
  device: "cuda"
  seed: 0
  progress_bar: true
